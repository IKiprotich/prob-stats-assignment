# -*- coding: utf-8 -*-
"""Probablity&Stats Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QKN4DClsBeti0DMf0eE9h7IP1KDJjzWj
"""



# Install required libraries (only need to run once)
!pip install pandas numpy matplotlib seaborn scipy scikit-learn openpyxl

# Import all libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import norm
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

print("‚úÖ All libraries installed and imported successfully!")

# Load your Excel file
try:
    df = pd.read_excel('Data.xlsx')
    print("‚úÖ Data loaded successfully!")
    print(f"Dataset shape: {df.shape}")
    print(f"Column names: {df.columns.tolist()}")
    print("\nFirst 10 rows:")
    print(df.head(10))
    print("\nBasic statistics:")
    print(df.describe())

except FileNotFoundError:
    print("‚ùå Data.xlsx not found. Please upload your file using the folder icon on the left.")

except Exception as e:
    print(f"‚ùå Error loading data: {e}")

# i. Plot Hours_Coding (x-axis) vs Num_Bugs (y-axis)
plt.figure(figsize=(10, 6))
plt.scatter(df['Hours_Coding'], df['Num_Bugs'], alpha=0.7, s=60, color='blue')
plt.xlabel('Hours Coding')
plt.ylabel('Number of Bugs')
plt.title('i. Relationship between Hours Coding and Number of Bugs')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("‚úÖ Scatter plot created successfully!")

# ii. Estimate Pearson's correlation coefficient r
correlation, p_value = stats.pearsonr(df['Hours_Coding'], df['Num_Bugs'])

print("ii. PEARSON'S CORRELATION ANALYSIS:")
print("=" * 50)
print(f"Correlation coefficient (r): {correlation:.4f}")
print(f"P-value: {p_value:.4f}")

# Interpret correlation
if abs(correlation) < 0.3:
    strength = "weak"
elif abs(correlation) < 0.7:
    strength = "moderate"
else:
    strength = "strong"

direction = "positive" if correlation > 0 else "negative"
print(f"Interpretation: {strength} {direction} correlation")

if p_value < 0.05:
    print("‚úÖ Statistically significant (p < 0.05)")
else:
    print("‚ùå Not statistically significant (p ‚â• 0.05)")

# iii. Develop regression equation and predict for 20 hours
X = df['Hours_Coding'].values.reshape(-1, 1)
y = df['Num_Bugs'].values

model = LinearRegression()
model.fit(X, y)

a = model.intercept_  # y-intercept
b = model.coef_[0]    # slope
r2 = model.score(X, y)  # R-squared

print("iii. REGRESSION ANALYSIS:")
print("=" * 50)
print(f"Regression equation: Num_Bugs = {a:.4f} + {b:.4f} √ó Hours_Coding")
print(f"R-squared: {r2:.4f}")

# Predict for 20 hours
predicted_bugs_20 = a + b * 20
print(f"\nüéØ PREDICTION FOR 20 HOURS:")
print(f"Predicted number of bugs: {predicted_bugs_20:.2f}")

# Plot regression line
plt.figure(figsize=(12, 6))
plt.scatter(df['Hours_Coding'], df['Num_Bugs'], alpha=0.7, s=60, label='Data points')

x_line = np.linspace(df['Hours_Coding'].min(), df['Hours_Coding'].max(), 100)
y_line = a + b * x_line
plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'y = {a:.2f} + {b:.2f}x')

plt.scatter([20], [predicted_bugs_20], color='red', s=150, marker='*',
           label=f'Prediction: 20h ‚Üí {predicted_bugs_20:.1f} bugs', zorder=5)

plt.xlabel('Hours Coding')
plt.ylabel('Number of Bugs')
plt.title('iii. Linear Regression with Prediction')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# iv. Develop frequency distribution table
bugs_freq = df['Num_Bugs'].value_counts().sort_index()

freq_table = pd.DataFrame({
    'Number_of_Bugs': bugs_freq.index,
    'Frequency': bugs_freq.values,
    'Relative_Frequency': bugs_freq.values / len(df),
    'Cumulative_Frequency': bugs_freq.cumsum().values,
    'Cumulative_Relative_Freq': bugs_freq.cumsum().values / len(df)
})

print("iv. FREQUENCY DISTRIBUTION TABLE:")
print("=" * 70)
print(freq_table.round(4).to_string(index=False))

# Also display as a nice table
from IPython.display import display
display(freq_table.round(4))

# vi. Overlay normal curve on histogram
mean_bugs = df['Num_Bugs'].mean()
std_bugs = df['Num_Bugs'].std()

plt.figure(figsize=(12, 6))

# Histogram with density
plt.hist(df['Num_Bugs'], bins=15, density=True, alpha=0.7, color='skyblue',
         edgecolor='black', label='Histogram')

# Normal curve overlay
x_norm = np.linspace(df['Num_Bugs'].min() - 1, df['Num_Bugs'].max() + 1, 100)
y_norm = norm.pdf(x_norm, mean_bugs, std_bugs)
plt.plot(x_norm, y_norm, 'r-', linewidth=3,
         label=f'Normal curve (Œº={mean_bugs:.2f}, œÉ={std_bugs:.2f})')

plt.xlabel('Number of Bugs')
plt.ylabel('Density')
plt.title('vi. Histogram with Normal Curve Overlay')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("vi. NORMAL DISTRIBUTION ANALYSIS:")
print("=" * 50)
print(f"Sample Mean (Œº): {mean_bugs:.4f}")
print(f"Sample Standard Deviation (œÉ): {std_bugs:.4f}")
print(f"Sample Size (n): {len(df)}")

# Test for normality
shapiro_stat, shapiro_p = stats.shapiro(df['Num_Bugs'])
print(f"\nNormality Test (Shapiro-Wilk):")
print(f"Test statistic: {shapiro_stat:.4f}")
print(f"P-value: {shapiro_p:.4f}")

if shapiro_p > 0.05:
    print("‚úÖ Data appears normally distributed (p > 0.05)")
else:
    print("‚ùå Data does not appear normally distributed (p ‚â§ 0.05)")